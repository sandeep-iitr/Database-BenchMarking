{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hbase in Python\n",
    "## Requirements\n",
    "- Hbase Installed\n",
    "- Start Hbase: ./start-hase.sh\n",
    "    - This will require the Zookeeper running, or in standalone mode the conf file specifications\n",
    "- Start the Hbase thrift server\n",
    "    - ./hbase thrift start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util: Create Table: Creates Table if not already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import happybase\n",
    "\n",
    "hostName='localhost'\n",
    "tableName='HBase-Test'\n",
    "column_family_name='cerebral-cortex'\n",
    "column_qualifier_name1='accx'\n",
    "column_qualifier_name2='accy'\n",
    "column_qualifier_name3='accz'\n",
    "\n",
    "# Creating the Table in which we will insert the data\n",
    "def CreateTable():\n",
    "    print(\"-\"*200)\n",
    "    print(\"CreateTable Called\")\n",
    "    connection = happybase.Connection(hostName)\n",
    "    connection.open()\n",
    "    tables = connection.tables()\n",
    "    if tableName.encode() in tables :\n",
    "        print(\"Table\", tableName,\"already exist\")\n",
    "        print(\"Current Tables in the Hbase:\\n\",tables)\n",
    "    else:\n",
    "        print(\"Current Tables in the Hbase:\\n\"+tables)\n",
    "        connection.create_table(\n",
    "             tableName,\n",
    "             {\n",
    "              column_family_name: dict(),  # use defaults\n",
    "              }\n",
    "             )\n",
    "        print('Table',tableName, 'created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util: Inserts Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a rowkey inserts the data point\n",
    "# rowkey: String\n",
    "# data=[TimeStamp,ax,ay,az], TimeStamp is used as rowkey\n",
    "def InsertData_Point(data):\n",
    "    print(\"-\"*200)\n",
    "    #print(\"InsertData_Point Called\")\n",
    "    connection = happybase.Connection(hostName)\n",
    "    connection.open()\n",
    "    table = connection.table(tableName)\n",
    "    \n",
    "    column_name1 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name1)\n",
    "    column_name2 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name2)\n",
    "    column_name3 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name3)\n",
    "    \n",
    "    # Format of Put\n",
    "    #table.put(b'row-key', {b'family:qual1': b'value1',\n",
    "    #                   b'family:qual2': b'value2'})\n",
    "    \n",
    "    # HBase does not have any notion of data types; \n",
    "    # all row keys, column names and column values are simply treated as raw byte strings.\n",
    "    # This means that data must be converted to byte strings \n",
    "    # in application before you pass it to HappyBase\n",
    "    rowkey=data[0].encode('utf-8')\n",
    "    ax=data[1].encode('utf-8')\n",
    "    ay=data[2].encode('utf-8')\n",
    "    az=data[3].encode('utf-8')\n",
    "    \n",
    "    table.put(rowkey, {column_name1: bytes(ax),column_name2: bytes(ay),column_name3: bytes(az)})\n",
    "    print(\"InsertData_Point Done\")\n",
    "    \n",
    "# Insert a batch of data points\n",
    "# rowkeylist: list(String)\n",
    "# datalist=list([ax,ay,az])\n",
    "def InsertData_Batch(datalist):\n",
    "    print(\"-\"*200)\n",
    "    #print(\"InsertData_Batch Called\")\n",
    "    connection = happybase.Connection(hostName)\n",
    "    connection.open()\n",
    "    table = connection.table(tableName)\n",
    "    \n",
    "    column_name1 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name1)\n",
    "    column_name2 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name2)\n",
    "    column_name3 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name3)\n",
    "    \n",
    "    \n",
    "    #batch_size acts as a threshold, when to send commands to HBase Server, 1000 bytes\n",
    "    with table.batch(batch_size=1000) as b:\n",
    "        #for i in range(len(rowkeylist)):\n",
    "        for rowkey,ax,ay,az in datalist:\n",
    "            #print(rowkey,ax,ay,az)\n",
    "            b.put(rowkey.encode('utf-8'), {column_name1: bytes(ax.encode('utf-8')),column_name2: bytes(ay.encode('utf-8')),column_name3: bytes(az.encode('utf-8'))})\n",
    "            \n",
    "    print(\"InsertData_Batch Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util: GetData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rowkey: is String\n",
    "def GetData(rowkey):\n",
    "    print(\"-\"*200)\n",
    "    print(\"GetData Called\")\n",
    "    connection = happybase.Connection(hostName)\n",
    "    connection.open()\n",
    "    table = connection.table(tableName)\n",
    "    key = rowkey.encode('utf-8')\n",
    "    column_name1 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name1)\n",
    "    column_name2 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name2)\n",
    "    column_name3 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name3)\n",
    "    \n",
    "    row = table.row(key)\n",
    "    #ax=row[column_name1.encode('utf-8')].decode()\n",
    "    #ay=row[column_name2.encode('utf-8')].decode()\n",
    "    #az=row[column_name3.encode('utf-8')].decode()\n",
    "    #print(\"Data:\", ax,ay,az)\n",
    "    print(row)\n",
    "\n",
    "def GetData_list(rowkeylist):\n",
    "    print(\"-\"*200)\n",
    "    print(\"GetData_list Called\")\n",
    "    connection = happybase.Connection(hostName)\n",
    "    connection.open()\n",
    "    table = connection.table(tableName)\n",
    "    \n",
    "    column_name1 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name1)\n",
    "    column_name2 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name2)\n",
    "    column_name3 = '{fam}:{qual}'.format(fam=column_family_name,qual=column_qualifier_name3)\n",
    "    \n",
    "    rowbyte=[]\n",
    "    for row in rowkeylist:\n",
    "        rowbyte.append(row.encode('utf-8'))\n",
    "    \n",
    "    rows = table.rows(rowbyte)\n",
    "    for key, data in rows:\n",
    "        print(key, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Inserting Point Data and Querying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "CreateTable Called\n",
      "Table HBase-Test already exist\n",
      "Current Tables in the Hbase:\n",
      " [b'Geomesa', b'Geomesa_GeoMesaTable_id', b'Geomesa_GeoMesaTable_z2', b'Geomesa_GeoMesaTable_z3', b'Geomesa_MetroInsight_id', b'Geomesa_MetroInsight_z2', b'Geomesa_MetroInsight_z3', b'HBase-Test']\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "InsertData_Point Done\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GetData Called\n",
      "{b'cerebral-cortex:accz': b'-9.43', b'cerebral-cortex:accy': b'1.32', b'cerebral-cortex:accx': b'2.45'}\n"
     ]
    }
   ],
   "source": [
    "CreateTable()\n",
    "InsertData_Point(['rowKey','2.45','1.32','-9.43'])\n",
    "GetData('rowKey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion using Batch in Hbase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "InsertData_Batch Done\n"
     ]
    }
   ],
   "source": [
    "InsertData_Batch([['rowKey1','2.45','1.32','-9.43'],\n",
    "                 ['rowKey2','3.45','2.32','-10.43'],\n",
    "                 ['rowKey3','4.45','3.32','-11.43'],\n",
    "                 ['rowKey4','5.45','4.32','-12.43']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying a Batch of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GetData_list Called\n",
      "b'rowKey1' {b'cerebral-cortex:accz': b'-9.43', b'cerebral-cortex:accy': b'1.32', b'cerebral-cortex:accx': b'2.45'}\n",
      "b'rowKey2' {b'cerebral-cortex:accz': b'-10.43', b'cerebral-cortex:accy': b'2.32', b'cerebral-cortex:accx': b'3.45'}\n",
      "b'rowKey3' {b'cerebral-cortex:accz': b'-11.43', b'cerebral-cortex:accy': b'3.32', b'cerebral-cortex:accx': b'4.45'}\n",
      "b'rowKey4' {b'cerebral-cortex:accz': b'-12.43', b'cerebral-cortex:accy': b'4.32', b'cerebral-cortex:accx': b'5.45'}\n"
     ]
    }
   ],
   "source": [
    "GetData_list(['rowKey1',\n",
    "             'rowKey2',\n",
    "             'rowKey3',\n",
    "             'rowKey4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BenchMarking:\n",
    "  - Create a synthetic dataset\n",
    "  - Batch Insert the data\n",
    "  - Perform different kind of queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV file with random data points\n",
    "\n",
    "# Data format: 'timestamp', 'acc_x','acc_y','acc_z'\n",
    "# acc_x ={0,10}, acc_y ={0,10}, acc_y ={0,10}\n",
    "# timestamp=(2017, to 2018)\n",
    "import csv\n",
    "import random\n",
    "import datetime \n",
    "import time\n",
    "\n",
    "#Name of file\n",
    "#Count of data itmes\n",
    "def CreateData(name,count):\n",
    "    with open(name, 'w') as csvfile:\n",
    "        fieldnames = ['timestamp', 'acc_x','acc_y','acc_z']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        #datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])\n",
    "        startDate = datetime.datetime(2017, 1, 1,0,0,0)\n",
    "        seconds_per_year=365*24*60*60\n",
    "        \n",
    "        for i in range(count):\n",
    "            acc_x=random.uniform(0, 10)\n",
    "            acc_y=random.uniform(0, 10)\n",
    "            acc_z=random.uniform(0, 10)\n",
    "            Date = startDate + datetime.timedelta(seconds=random.uniform(0, seconds_per_year))\n",
    "            TimeStamp = time.mktime(Date.timetuple())\n",
    "            writer.writerow({'timestamp': TimeStamp, 'acc_x': acc_x,'acc_y': acc_y,'acc_z': acc_z})\n",
    "            \n",
    "CreateData('test.csv',10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the Synthetic DataSet into the Hbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InsertData_BenchMark(name):\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
